{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee353e42-ff58-4955-9608-12865bd0950e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Default notebook\n",
    "\n",
    "This default notebook is executed using Databricks Workflows as defined in resources/bundle.job.yml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../\"))\n",
    "\n",
    "run_date = datetime.strptime(dbutils.widgets.get(\"run_date\"), '%Y-%m-%d')\n",
    "start_date = run_date - timedelta(days=1)\n",
    "ctr_catalog_name = dbutils.widgets.get(\"ctr_catalog_name\")\n",
    "raw_catalog_name = dbutils.widgets.get(\"raw_catalog_name\")\n",
    "stg_catalog_name = dbutils.widgets.get(\"stg_catalog_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bca260b-13d1-448f-8082-30b60a85c9ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_xml, schema_of_xml\n",
    "from lib.el import DataLoader, DeltaDataLoader\n",
    "\n",
    "store_data_ingestion = (spark.read\n",
    "    .table(f\"{ctr_catalog_name}.loading.data_ingestion\")\n",
    "    .select(\n",
    "        \"schema_name\",\n",
    "        \"table_name\",\n",
    "        \"primary_key\", \n",
    "        \"filter\",\n",
    "        \"selected\")\n",
    "    .where(\"LOWER(schema_name) = 'sales' AND LOWER(table_name) = 'store'\")\n",
    ").collect()[0]\n",
    "\n",
    "schema_name = store_data_ingestion[\"schema_name\"]\n",
    "table_name = store_data_ingestion[\"table_name\"]\n",
    "primary_key = store_data_ingestion[\"primary_key\"].replace(\" \", \"\").split(\",\")\n",
    "selected = None if store_data_ingestion[\"selected\"] is None else store_data_ingestion[\"selected\"].replace(\" \", \"\").split(\",\")\n",
    "\n",
    "store_data_loader = DeltaDataLoader(\n",
    "    catalog_name = raw_catalog_name,\n",
    "    schema_name = schema_name,\n",
    "    table_name = table_name,\n",
    "    primary_key = primary_key,\n",
    "    selected = selected\n",
    ")\n",
    "\n",
    "if spark.catalog.tableExists(f\"{stg_catalog_name}.{schema_name}.{table_name}\"):\n",
    "    start_date_filter = f\"TO_DATE('{start_date.strftime('%Y-%m-%d')}', 'yyyy-MM-dd')\"\n",
    "    filter = store_data_ingestion[\"filter\"].replace(\":start_date\", start_date_filter)\n",
    "else:\n",
    "    filter = None\n",
    "\n",
    "store_data_loader.extract(filter)\n",
    "\n",
    "if store_data_loader.df.count() > 0:\n",
    "    demographics_schema = schema_of_xml(store_data_loader.df.first()[\"Demographics\"])\n",
    "\n",
    "    df_store_demographics = (store_data_loader.df\n",
    "        .withColumn(\n",
    "            \"Demographics\",\n",
    "            from_xml(\"Demographics\", demographics_schema).alias(\"data\")\n",
    "        )\n",
    "\n",
    "        .select(\n",
    "            *primary_key, \n",
    "            \"Demographics.AnnualRevenue\",\n",
    "            \"Demographics.AnnualSales\",\n",
    "            \"Demographics.BankName\",\n",
    "            \"Demographics.Brands\",\n",
    "            \"Demographics.BusinessType\",\n",
    "            \"Demographics.Internet\",\n",
    "            \"Demographics.NumberEmployees\",\n",
    "            \"Demographics.Specialty\",\n",
    "            \"Demographics.SquareFeet\",\n",
    "            \"Demographics.YearOpened\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    spark.sql(f\"create schema if not exists {stg_catalog_name}.{schema_name}\")\n",
    "\n",
    "    demographics_table_name = f\"{stg_catalog_name}.{schema_name}.StoreDemographics\"\n",
    "\n",
    "    (DataLoader\n",
    "        .fromDataFrame(df_store_demographics, *primary_key)\n",
    "        .load_into(demographics_table_name)\n",
    "    )\n",
    "\n",
    "    (store_data_loader\n",
    "        .apply(lambda df: df.select([col for col in store_data_loader.df.columns if col != \"Demographics\"]))\n",
    "        .load_into(f\"{stg_catalog_name}.{schema_name}.Store\")\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "notebook",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
